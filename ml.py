# -*- coding: utf-8 -*-
"""ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sALS_MvvzcKYqlB8Xj-3wtGD0AjrzDcX
"""

# Feacher Engineering---- Data clean and Preprocess

# workflow of ML
# Data integration--- Data cleaning and preprocessing---- select ML model---model training---model evaluation

#Data Dividation
# Data--x,y
# x=x_train,x_test
# y=y_train ,y_test

import pandas as pd

df=pd.read_csv("/content/placement - placement.csv")

df.head(2)

df.shape

# input data
x=df.drop(columns=['placed'])
x

# targeted data
y=df['placed']
y

from sklearn.model_selection import train_test_split

x_train ,x_test, y_train ,y_test =train_test_split(x,y,test_size=0.2,random_state=42)

# test=20%
# train=80%

x_train

print("data shape",df.shape)
print("------------------")
print("x_data shape",x.shape)
print("x_train data shape",x_train.shape)
print("x_test data shape",x_test.shape)
print("--------------")
print("y data shape",y.shape)
print("Y_train data shape",y_train.shape)
print("y_test data shape",y_test.shape)

df=pd.read_csv("/content/covid_toy - covid_toy (1).csv")

df

# input data
x=df.drop(columns=['has_covid'])
x

# target data
y=df['has_covid']
y

x_train ,x_test, y_train ,y_test =train_test_split(x,y,test_size=0.2,random_state=21)

x_train

df

df.isnull().sum()

from sklearn.impute import SimpleImputer

si=SimpleImputer(strategy='mean')

df['fever']=si.fit_transform(df[['fever']])
# fit means learn the parameters and transform mean apply
# on that data

df.isnull().sum()

df.head(3)

df['gender'].value_counts()

df['gender']=df['gender'].map({"Female":0,"Male":1})

df

df['cough']=df['cough'].map({"Mild":0,"Strong":1})

df['city'].value_counts()

df['city']=df['city'].map({"Kolkata":0,"Bangalore":1,"Delhi":2,"Mumbai":3})

df

x=df.drop(columns=['has_covid'])
x

y=df['has_covid']
y

x_train ,x_test, y_train ,y_test =train_test_split(x,y,test_size=0.2,random_state=21)

x.shape

print("data shape",df.shape)
print("------------------")
print("x_data shape",x.shape)
print("_xtrain data shape",x_train.shape)
print("x_test data shape",x_test.shape)
print("--------------")
print("y data shape",y.shape)
print("Y_train data shape",y_train.shape)
print("y_test data shape",y_test.shape)

df=pd.read_csv("/content/tips - tips.csv")

df

df.isnull().sum()

df['time'].value_counts()

df['time']=df['time'].map({"Dinner":0,"Lunch":1})

df['sex']=df['sex'].map({"Male":0,"Female":1})

df['smoker']=df['smoker'].map({"Yes":0,"No":1})

df

df['day'].value_counts()

df['day']=df['day'].map({"Sat":2,"Thur":0,"Fri":1,"Sun":3})

df

x=df.drop(columns=['total_bill'])
x

y=df['total_bill']
y

x_train ,x_test, y_train ,y_test =train_test_split(x,y,test_size=0.2,random_state=10)

x_train.shape

print("data shape",df.shape)
print("------------------")
print("x_data shape",x.shape)
print("_xtrain data shape",x_train.shape)
print("x_test data shape",x_test.shape)
print("--------------")
print("y data shape",y.shape)
print("Y_train data shape",y_train.shape)
print("y_test data shape",y_test.shape)

import pandas as pd

from sklearn.model_selection import train_test_split

df=pd.read_csv("/content/insurance - insurance.csv")

df

df['sex']=df['sex'].map({'female':0,'male':1})

df['region'].value_counts()

df['region']=df['region'].map({'southeast':0,'southwest':1,'northwest':2,'northeast':3})

df

df.isnull().sum()

df['smoker']=df['smoker'].map({'yes':0,'no':1})

x=df.drop(columns=['charges'])

y=df['charges']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=20)

x_test

print("data shape",df.shape)
print("------------------")
print("x_data shape",x.shape)
print("x_train data shape",x_train.shape)
print("x_test data shape",x_test.shape)
print("--------------")
print("y data shape",y.shape)
print("Y_train data shape",y_train.shape)
print("y_test data shape",y_test.shape)

df=pd.read_csv("/content/userbehaviour - userbehaviour.csv")

df

df.isnull().sum()

x=df.drop(columns=['Average Spent on App (INR)'])

y=df['Average Spent on App (INR)']

x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.8,random_state=3)

print("data shape",df.shape)
print("------------------")
print("x_data shape",x.shape)
print("x_train data shape",x_train.shape)
print("x_test data shape",x_test.shape)
print("--------------")
print("y data shape",y.shape)
print("Y_train data shape",y_train.shape)
print("y_test data shape",y_test.shape)

df=pd.read_csv("/content/titanic - titanic.csv")

df.head(3)

df=pd.read_csv("/content/supply_chain - supply_chain.csv")

df.head(4)

df.shape

df=pd.read_csv("/content/Attrition - Attrition.csv")

df.head(2)

df=pd.read_csv("/content/linkedin-reviews - linkedin-reviews.csv")

df

# Machin---> works on numbers
# Data--> Normal Distribution
# Standardization ---> mean=0, standard deviation =1

import pandas as pd

import numpy as np

df=pd.read_csv("/content/covid_toy - covid_toy (1).csv")

df

from sklearn.model_selection import train_test_split

df.isnull().sum()

df['fever']=df['fever'].fillna(df['fever'].mean())

df.isnull().sum()

df['gender']=df['gender'].map({"Male":0,"Female":1})

df['cough']=df['cough'].map({"Mild":0,"Strong":1})



x=df.drop(columns=['has_covid'])

y=df['has_covid']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=20)

np.round(x_train.describe(),2)

# Now we will apply Standardization

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

x_train_sc=sc.fit_transform(x_train)

x_train_new=pd.DataFrame(x_train_sc,columns=x.columns)

np.round(x_train_new.describe(),2)

df=pd.read_csv("/content/click - click.csv")

df['Gender']=df['Gender'].map({"Male":0,"Female":1})

df=df.drop(columns=['Ad Topic Line','Timestamp','City','Country'])

df.head(2)

x=df.drop(columns=['Clicked on Ad'])

y=df['Clicked on Ad']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

sc=StandardScaler()

x_train_sc=sc.fit_transform(x_train)

x_train_new=pd.DataFrame(x_train_sc,columns=x.columns)

np.round(x_train_new.describe(),2)

df=pd.read_csv("/content/placement - placement.csv")

df

x=df.drop(columns=['placed'])

x

y=df['placed']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=34)

np.round(x_train.describe(),2)

sc=StandardScaler()

x_train_sc=sc.fit_transform(x_train)

x_train_new=pd.DataFrame(x_train_sc,columns=x.columns)

np.round(x_train_new.describe(),2)

df=pd.read_csv("/content/tips - tips.csv")

df

df['sex']=df['sex'].map({"Female":0,"Male":1})

df['smoker']=df['smoker'].map({"Yes":0,"No":1})

df['day'].value_counts()

df['day']=df['day'].map({"Sat":0,"Sun":1,"Thur":2,"Fri":3})

df['time'].value_counts()

df['time']=df['time'].map({"Dinner":0,"Lunch":1})

df

x=df.drop(columns=['total_bill'])

y=df['total_bill']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

np.round(x_train.describe(),2)

sc=StandardScaler()

x_train_sc=sc.fit_transform(x_train)

x_train_new=pd.DataFrame(x_train_sc,columns=x.columns)

np.round(x_train_new.describe(),2)

import pandas as pd

import numpy as np

df=pd.read_csv("/content/tips - tips.csv")

df.head(2)

df.isnull().sum()

df['day'].value_counts()

df['time'].value_counts()

df['sex']=df['sex'].map({"Female":0,"Male":1})
df['smoker']=df['smoker'].map({"Yes":0,"No":1})
df['day']=df['day'].map({"Sat":0,"Sun":1,"Thur":2,"Fri":3})
df['time']=df['time'].map({"Dinner":0,"Lunch":1})

df

x=df.drop(columns=['total_bill'])
y=df['total_bill']

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

np.round(x_train.describe(),2)

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

x_train_sc=sc.fit_transform(x_train)

x_train_new=pd.DataFrame(x_train_sc,columns=x.columns)

np.round(x_train_new.describe(),2)

